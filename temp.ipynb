{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "RESPONSE = \"two_year_recid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:26:08<00:00, 861.45s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [1:10:26<14:04, 844.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:24:33<00:00, 845.60s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [14:10<1:10:54, 850.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [28:52<57:56, 869.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [43:03<43:02, 860.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [57:13<28:32, 856.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [1:11:31<14:16, 856.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:25:56<00:00, 859.39s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [43:14<43:15, 865.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [57:26<28:39, 859.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n",
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:26:07<00:00, 861.27s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [14:12<1:11:02, 852.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP error z0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:25:51<00:00, 858.63s/it]\n",
      "100%|██████████| 6/6 [1:26:31<00:00, 865.30s/it]\n"
     ]
    }
   ],
   "source": [
    "#percentiles = [p for p in range(0,20,2)]+[p for p in range(20,80, 10)]\n",
    "percentiles = [0,5,25]+[50,80]\n",
    "#TODO test missing = Sensitive in case code crashes\n",
    "missing=[\"priors_count\", 'age_factor_Greater than 45', \"is_Caucasian\"]#, \"gender_factor\", ]\n",
    "all_results2 = {\"Full data\": {}, \"Averaged results\": {} }\n",
    "RUNS = 6\n",
    "for miss in missing:\n",
    "    for sensitive in [\"is_Caucasian\", \"gender_factor\"]:\n",
    "        recid_results = utils.test_bench(data = \"compas\", pred = RESPONSE, missing = miss, sensitive=sensitive,\n",
    "                            percentiles = percentiles, n_runs=RUNS, differencing=False)\n",
    "        all_results2[\"Full data\"][miss+\"_\"+sensitive+\"_\"+\"recid\"] = recid_results[\"Full data\"]\n",
    "        all_results2[\"Averaged results\"][miss+\"_\"+sensitive+\"_\"+\"recid\"] = recid_results[\"Averaged results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import json\n",
    "with open(Path(\"raw_data/self_run_14_08.json\"), 'w') as f:\n",
    "    json.dump(all_results2, f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "NAME_KEYS = {\"coldel\": \"Column deletion\",\n",
    "             \"cca\": \"CCA\",\n",
    "             \"mice_def\": \"Chained Eqaution\",\n",
    "             \"mean\": \"Mean\",\n",
    "             \"log_reg\": \"Logistic Regression\",\n",
    "             \"svm\": \"SVM\",\n",
    "             \"knn\": \"KNN\",\n",
    "             \"rf_cat\": \"Random Forest\",\n",
    "             \"fair_reg_995\": \"Fairness aware imputation lambda = 0.995\",\n",
    "             \"fair_reg_985\": \"Fairness aware imputation lambda = 0.985\",\n",
    "             \"eosum\": \"Sum of eqality of odds\",\n",
    "             \"acc\":\"Accuracy\",\n",
    "             \"pp\": \"Predictive Parity\",\n",
    "             \"spd\": \"Statistical Parity Difference\",\n",
    "             \"tpr0\": \"True positive rate Z=0\",\n",
    "             \"tpr1\": \"True positive rate Z=1\",\n",
    "             \"tnr0\": \"True negative rate Z=0\",\n",
    "             \"tnr1\": \"True negative rate Z=1\",\n",
    "             \"eo0\":\"Equality of odds Y=0\",\n",
    "             \"eo1\":\"Equality of odds Y=1\"}\n",
    "\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 25}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTATIONS = [\"fair_reg_995\", \"cca\", \"fair_reg_985\", \"mean\", \"mice_def\", \"coldel\"]\n",
    "MODELS = [\"log_reg\", \"rf_cat\", \"svm\", \"knn\"]\n",
    "METRICS = [\"spd\", \"eo0\",\"eo1\", \"eosum\", \"pp\", \"acc\", \"tpr0\", \"tpr1\", \"tnr0\", \"tnr1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"crime_factor_is_Caucasian_recid\"][\"0\"][miss][metr][mod][imp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing=[\"priors_count\", 'age_factor_Greater than 45', \"is_Caucasian\"]#, \"gender_factor\", ]\n",
    "#all_results2 = {\"Full data\": {}, \"Averaged results\": {} }\n",
    "RUNS = 4\n",
    "a = [\"is_Caucasian\", \"gender_factor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1620x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for miss in [\"mcar\", \"mar\"]:\n",
    "    for metr in METRICS:\n",
    "        for mod in MODELS:\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(22.5, 12.5)\n",
    "            for imp in IMPUTATIONS:\n",
    "                key = \"|\".join([miss,metr,mod,imp])\n",
    "                data = all_results2[\"Full data\"][\"priors_count_is_Caucasian_recid\"][\"0\"][miss][metr][mod][imp]\n",
    "                plt.plot(percentiles, data,\n",
    "                 label=NAME_KEYS[imp])\n",
    "            plt.title(\"Average performance of imputation techniques on COMPAS for \"+ NAME_KEYS[mod])\n",
    "            plt.xlabel(\"Missingness percent\")\n",
    "            plt.ylabel(NAME_KEYS[metr])\n",
    "            #plt.ylim(0.6, 1.01)\n",
    "            plt.legend()\n",
    "            plt.savefig(Path(\"temp2/\"+miss+\"_\"+metr+\"_\"+mod+\"_\"+miss+\".png\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1620x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for miss in [\"mcar\", \"mar\"]:\n",
    "    for metr in METRICS:\n",
    "        for mod in MODELS:\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(22.5, 12.5)\n",
    "            for imp in IMPUTATIONS:\n",
    "                key = \"|\".join([miss,metr,mod,imp])\n",
    "                data = all_results2[\"Averaged results\"][\"priors_count_is_Caucasian_recid\"][key]\n",
    "                plt.plot(percentiles, data,\n",
    "                 label=NAME_KEYS[imp])\n",
    "            plt.title(\"Average performance of imputation techniques on COMPAS for \"+ NAME_KEYS[mod])\n",
    "            plt.xlabel(\"Missingness percent\")\n",
    "            plt.ylabel(NAME_KEYS[metr])\n",
    "            #plt.ylim(0.6, 1.01)\n",
    "            plt.legend()\n",
    "            plt.savefig(Path(\"temp2/\"+miss+\"_\"+metr+\"_\"+mod+\"_\"+miss+\".png\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:46:08<00:00, 1592.03s/it]\n",
      "100%|██████████| 4/4 [1:49:30<00:00, 1642.65s/it]\n"
     ]
    }
   ],
   "source": [
    "all_results_69 = {\"Full data\": {}, \"Averaged results\": {} }\n",
    "RUNS = 4\n",
    "try:\n",
    "    for miss in [\"x_2\", \"x_5\"]:\n",
    "        sensitive = \"x_1\"\n",
    "        RESPONSE = \"y\"\n",
    "        synth_results = utils.test_bench(data = \"simple\", pred = RESPONSE, missing = miss, sensitive=sensitive,\n",
    "                                    percentiles = percentiles, n_runs=RUNS, differencing=False)\n",
    "        all_results_69[\"Full data\"][miss+\"_\"+sensitive+\"_\"+\"synth\"] = synth_results[\"Full data\"]\n",
    "        all_results_69[\"Averaged results\"][miss+\"_\"+sensitive+\"_\"+\"synth\"] = synth_results[\"Averaged results\"]\n",
    "except Exception as e:\n",
    "    print(\"Exception:\", e)\n",
    "    print(\"SIMPLE SYNTH\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(Path(\"raw_data/self_simple_synth_run_14_08.json\"), 'w') as f:\n",
    "    json.dump(all_results_69, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1620x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for miss in [\"mcar\", \"mar\"]:\n",
    "    for metr in METRICS:\n",
    "        for mod in MODELS:\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(22.5, 12.5)\n",
    "            for imp in IMPUTATIONS:\n",
    "                key = \"|\".join([miss,metr,mod,imp])\n",
    "                data = all_results_69[\"Averaged results\"][\"x_5_x_1_synth\"][key]\n",
    "                plt.plot(percentiles, data,\n",
    "                 label=NAME_KEYS[imp])\n",
    "            plt.title(\"Average performance of imputation techniques on COMPAS for \"+ NAME_KEYS[mod])\n",
    "            plt.xlabel(\"Missingness percent\")\n",
    "            plt.ylabel(NAME_KEYS[metr])\n",
    "            #plt.ylim(0.6, 1.01)\n",
    "            plt.legend()\n",
    "            plt.savefig(Path(\"temp/temp_synth_x_5/\"+miss+\"_\"+metr+\"_\"+mod+\"_\"+miss+\".png\"))\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, alpha):\n",
    "    z = np.exp(-x+alpha)\n",
    "    sig = 1 / (1 + z)\n",
    "    return sig\n",
    "size = 10000\n",
    "x_1 = np.random.binomial(1, 0.45, size=size)\n",
    "x_2 = np.random.binomial(1, 0.65, size=size)\n",
    "x_3 = np.random.normal(0,1,size)\n",
    "x_4 = np.random.binomial(1, 0.3, size=size)\n",
    "x_5 = [np.random.binomial(1, 0.5+0.2*val, size=1)[0] for val in x_1]\n",
    "y = np.around(sigmoid(x_1*0.3+x_2+x_3, alpha=0.8)).astype(int)\n",
    "synth_cat_train = pd.DataFrame({\"y\": y, \"x_1\": x_1, \"x_2\":x_2, \"x_3\": x_3, \"x_4\":x_4, \"x_5\":x_5})\n",
    "synth_cat_train[\"miss\"] = np.around(sigmoid(x_1+y+x_3+x_4+x_5, 1)).astype(int)\n",
    "synth_cat_train = synth_cat_train[synth_cat_train[\"miss\"]==0]\n",
    "synth_cat_train.drop(\"miss\", axis = 1, inplace = True)\n",
    "#synth_cat_test = synth_cat.iloc[:round(0.333*size), :]\n",
    "#synth_cat_train = synth_cat.iloc[round(0.333*size):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6742"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(sigmoid(x_1+y+x_3+x_4+x_5, 1)).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3000\n",
    "x_1 = np.random.binomial(1, 0.45, size=size)\n",
    "x_2 = np.random.binomial(1, 0.65, size=size)\n",
    "x_3 = np.random.normal(0,1,size)\n",
    "x_4 = np.random.binomial(1, 0.3, size=size)\n",
    "x_5 = [np.random.binomial(1, 0.5+0.2*val, size=1)[0] for val in x_1]\n",
    "y = np.around(sigmoid(x_1*0.3+x_2+x_3, alpha=0.8)).astype(int)\n",
    "synth_cat_test = pd.DataFrame({\"y\": y, \"x_1\": x_1, \"x_2\":x_2, \"x_3\": x_3, \"x_4\":x_4, \"x_5\":x_5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3258"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(synth_cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred):\n",
    "    # Assumes numpy arrays(\n",
    "    try:\n",
    "        tpr = sum([1 if t == p and p == 1 else 0 for t,\n",
    "                  p in zip(true, pred)])/(sum(true))\n",
    "    except:\n",
    "        tpr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "\n",
    "    try:\n",
    "        tnr = sum([1 if t == p and p == 0 else 0 for t,\n",
    "                  p in zip(true, pred)])/(len(true)-sum(true))\n",
    "    except:\n",
    "        tnr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "    fpr = 1-tnr\n",
    "    fnr = 1-tpr\n",
    "    #Old return structure. Converted to vanilla dict for json compatibility\n",
    "    #return pd.DataFrame({\"Predicted true\": [tpr, fpr],\n",
    "    #                     \"Predicted false\": [fnr, tnr]}, index=[\"Is true\", \"Is false\"])\n",
    "    return {\"Predicted true\": [tpr, fpr],\n",
    "            \"Predicted false\": [fnr, tnr]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1120\n",
      "z=1 {'Predicted true': [0.6703146374829001, 0.0], 'Predicted false': [0.3296853625170999, 1.0]}\n",
      "accuracy 0.8503105590062112\n",
      "-1076\n",
      "z=1 {'Predicted true': [0.39006211180124223, 0.0], 'Predicted false': [0.6099378881987578, 1.0]}\n",
      "accuracy 0.6467625899280576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = LogisticRegression()\n",
    "clf.fit(synth_cat_train.drop(\"y\", axis = 1), synth_cat_train[\"y\"])\n",
    "x_test = synth_cat_test.drop(\"y\", axis = 1)\n",
    "for s in [0,1]:\n",
    "    y_test = synth_cat_test[synth_cat_test[\"x_1\"]==s]\n",
    "    y_test = y_test[\"y\"]\n",
    "    pred = clf.predict(x_test[x_test[\"x_1\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-885\n",
      "z=1 {'Predicted true': [0.9917920656634747, 0.0], 'Predicted false': [0.008207934336525335, 1.0]}\n",
      "accuracy 0.9962732919254659\n",
      "-591\n",
      "z=1 {'Predicted true': [0.9925465838509316, 0.0], 'Predicted false': [0.007453416149068359, 1.0]}\n",
      "accuracy 0.99568345323741\n"
     ]
    }
   ],
   "source": [
    "size = 10000\n",
    "x_1 = np.random.binomial(1, 0.45, size=size)\n",
    "x_2 = np.random.binomial(1, 0.65, size=size)\n",
    "x_3 = np.random.normal(0,1,size)\n",
    "x_4 = np.random.binomial(1, 0.3, size=size)\n",
    "x_5 = [np.random.binomial(1, 0.5+0.2*val, size=1)[0] for val in x_1]\n",
    "y = np.around(sigmoid(x_1*0.3+x_2+x_3, alpha=0.8)).astype(int)\n",
    "synth_cat_train = pd.DataFrame({\"y\": y, \"x_1\": x_1, \"x_2\":x_2, \"x_3\": x_3, \"x_4\":x_4, \"x_5\":x_5})\n",
    "synth_cat_train[\"miss\"] = np.random.binomial(1,p = 0.67, size = size)\n",
    "synth_cat_train = synth_cat_train[synth_cat_train[\"miss\"]==0]\n",
    "synth_cat_train.drop(\"miss\", axis = 1, inplace = True)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(synth_cat_train.drop(\"y\", axis = 1), synth_cat_train[\"y\"])\n",
    "x_test = synth_cat_test.drop(\"y\", axis = 1)\n",
    "for s in [0,1]:\n",
    "    y_test = synth_cat_test[synth_cat_test[\"x_1\"]==s]\n",
    "    y_test = y_test[\"y\"]\n",
    "    pred = clf.predict(x_test[x_test[\"x_1\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-878\n",
      "z=1 {'Predicted true': [0.8002735978112175, 0.16723549488054612], 'Predicted false': [0.19972640218878246, 0.8327645051194539]}\n",
      "accuracy 0.8180124223602484\n",
      "-590\n",
      "z=1 {'Predicted true': [0.8472049689440994, 0.20170940170940166], 'Predicted false': [0.15279503105590064, 0.7982905982905983]}\n",
      "accuracy 0.8266187050359712\n"
     ]
    }
   ],
   "source": [
    "size = 10000\n",
    "x_1 = np.random.binomial(1, 0.45, size=size)\n",
    "x_2 = np.random.binomial(1, 0.65, size=size)\n",
    "x_3 = np.random.normal(0,1,size)\n",
    "x_4 = np.random.binomial(1, 0.3, size=size)\n",
    "x_5 = [np.random.binomial(1, 0.5+0.2*val, size=1)[0] for val in x_1]\n",
    "y = np.around(sigmoid(x_1*0.3+x_2+x_3, alpha=0.8)).astype(int)\n",
    "synth_cat_train = pd.DataFrame({\"y\": y, \"x_1\": x_1, \"x_3\": x_3, \"x_4\":x_4, \"x_5\":x_5})\n",
    "clf = LogisticRegression()\n",
    "clf.fit(synth_cat_train.drop(\"y\", axis = 1), synth_cat_train[\"y\"])\n",
    "x_test = synth_cat_test.drop([\"y\",\"x_2\"], axis = 1)\n",
    "for s in [0,1]:\n",
    "    y_test = synth_cat_test[synth_cat_test[\"x_1\"]==s]\n",
    "    y_test = y_test[\"y\"]\n",
    "    pred = clf.predict(x_test[x_test[\"x_1\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "size = 10000\n",
    "x_1 = np.random.binomial(1, 0.45, size=size)\n",
    "x_2 = np.random.binomial(1, 0.65, size=size)\n",
    "x_3 = np.random.normal(0,1,size)\n",
    "x_4 = np.random.binomial(1, 0.3, size=size)\n",
    "x_5 = [np.random.binomial(1, 0.5+0.2*val, size=1)[0] for val in x_1]\n",
    "y = np.around(sigmoid(x_1*0.3+x_2+x_3, alpha=0.8)).astype(int)\n",
    "synth_cat_train = pd.DataFrame({\"y\": y, \"x_1\": x_1, \"x_2\":x_2, \"x_3\": x_3, \"x_4\":x_4, \"x_5\":x_5})\n",
    "synth_cat_train[\"x_2\"].mean(dropna=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_cat_train[\"miss\"] = np.around(sigmoid(x_1+y+x_2+x_3+x_4+x_5, -2.2)).astype(int)\n",
    "miss_index = synth_cat_train[synth_cat_train[\"miss\"]==1].index\n",
    "synth_cat_train[\"x_2\"] = synth_cat_train[\"x_2\"].mask(synth_cat_train.index.isin(miss_index),\n",
    "                                                        other=np.nan)\n",
    "synth_cat_train.drop(\"miss\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y         0\n",
       "x_1       0\n",
       "x_2    9981\n",
       "x_3       0\n",
       "x_4       0\n",
       "x_5       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_cat_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=0)\n",
    "imputer.fit(synth_cat_train)\n",
    "synth_cat_train = pd.DataFrame(imputer.transform(synth_cat_train), columns=synth_cat_train.columns)\n",
    "synth_cat_train[\"x_2\"] = synth_cat_train[\"x_2\"].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.297408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.378053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.326792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.866432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.447766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y  x_1  x_2       x_3  x_4  x_5\n",
       "0  1.0  0.0  1.0  1.297408  0.0  1.0\n",
       "1  1.0  1.0  1.0  0.378053  0.0  1.0\n",
       "2  1.0  0.0  1.0  1.326792  1.0  1.0\n",
       "3  0.0  0.0  1.0 -1.866432  0.0  1.0\n",
       "4  0.0  0.0  1.0 -1.447766  0.0  0.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_cat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-906.0\n",
      "z=1 {'Predicted true': [0.810918774966711, 0.15486725663716816], 'Predicted false': [0.18908122503328895, 0.8451327433628318]}\n",
      "accuracy 0.829607250755287\n",
      "-606.0\n",
      "z=1 {'Predicted true': [0.8428761651131824, 0.17845117845117842], 'Predicted false': [0.15712383488681758, 0.8215488215488216]}\n",
      "accuracy 0.833457249070632\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(synth_cat_train.drop(\"y\", axis = 1), synth_cat_train[\"y\"])\n",
    "x_test = synth_cat_test.drop(\"y\", axis = 1)\n",
    "for s in [0,1]:\n",
    "    y_test = synth_cat_test[synth_cat_test[\"x_1\"]==s]\n",
    "    y_test = y_test[\"y\"]\n",
    "    pred = clf.predict(x_test[x_test[\"x_1\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-906.0\n",
      "z=1 {'Predicted true': [0.810918774966711, 0.15486725663716816], 'Predicted false': [0.18908122503328895, 0.8451327433628318]}\n",
      "accuracy 0.829607250755287\n",
      "-606.0\n",
      "z=1 {'Predicted true': [0.8428761651131824, 0.17845117845117842], 'Predicted false': [0.15712383488681758, 0.8215488215488216]}\n",
      "accuracy 0.833457249070632\n"
     ]
    }
   ],
   "source": [
    "synth_cat_train[\"miss\"] = np.around(sigmoid(x_1+y+x_3+x_4+x_5, -2.2)).astype(int)\n",
    "miss_index = synth_cat_train[synth_cat_train[\"miss\"]==1].index\n",
    "synth_cat_train[\"x_2\"] = synth_cat_train[\"x_2\"].mask(synth_cat_train.index.isin(miss_index),\n",
    "                                                        other=np.nan)\n",
    "synth_cat_train.drop(\"miss\", axis = 1, inplace = True)\n",
    "synth_cat_train.fillna(synth_cat_train[\"x_2\"].mode(dropna=True)[0], inplace=True)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(synth_cat_train.drop(\"y\", axis = 1), synth_cat_train[\"y\"])\n",
    "x_test = synth_cat_test.drop(\"y\", axis = 1)\n",
    "for s in [0,1]:\n",
    "    y_test = synth_cat_test[synth_cat_test[\"x_1\"]==s]\n",
    "    y_test = y_test[\"y\"]\n",
    "    pred = clf.predict(x_test[x_test[\"x_1\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_cat_train[\"x_2\"].mode(dropna=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6b5d6a7d9324dc6141b12d74f79997d922c129aaadb2c82c0fa5c003a2c41f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

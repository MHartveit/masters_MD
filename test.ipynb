{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred):\n",
    "    # Assumes numpy arrays(\n",
    "    try:\n",
    "        tpr = sum([1 if t == p and p == 1 else 0 for t,\n",
    "                  p in zip(true, pred)])/(sum(true))\n",
    "    except:\n",
    "        tpr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "\n",
    "    try:\n",
    "        tnr = sum([1 if t == p and p == 0 else 0 for t,\n",
    "                  p in zip(true, pred)])/(len(true)-sum(true))\n",
    "    except:\n",
    "        tnr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "    fpr = 1-tnr\n",
    "    fnr = 1-tpr\n",
    "    #Old return structure. Converted to vanilla dict for json compatibility\n",
    "    #return pd.DataFrame({\"Predicted true\": [tpr, fpr],\n",
    "    #                     \"Predicted false\": [fnr, tnr]}, index=[\"Is true\", \"Is false\"])\n",
    "    return pd.DataFrame({\"Predicted true\": [tpr, fpr],\n",
    "                \"Predicted false\": [fnr, tnr]}, index = [\"Is true\", \"Is false\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compas_cleaning(df):\n",
    "    new_df = df.dropna()\n",
    "    new_df = new_df[(new_df[\"days_b_screening_arrest\"]<=30)&\n",
    "                    (new_df[\"days_b_screening_arrest\"]>=-30)&\n",
    "                    (new_df[\"is_recid\"]!=-1)&\n",
    "                    (new_df[\"c_charge_degree\"]!=\"O\")]\n",
    "    new_df[\"length_of_stay\"] = ((pd.to_datetime(df[\"c_jail_out\"])-pd.to_datetime(df[\"c_jail_in\"])).dt.days)\n",
    "    new_df[\"length_of_stay\"] = new_df[\"length_of_stay\"].astype(int)\n",
    "    \n",
    "    #Perhaps limit dataset to only black and white participants\n",
    "    new_df[\"is_Caucasian\"] = new_df[\"race\"].apply(lambda x: 1 if x==\"Caucasian\" else 0)\n",
    "    new_df.drop(labels = [\"c_jail_out\", \"c_jail_in\", \"days_b_screening_arrest\", \"is_recid\", \"race\"],axis = 1, inplace = True)\n",
    "    if \"v_score_text\" in new_df.columns:\n",
    "        new_df.columns = [\"score_text\" if col == \"v_score_text\" else col for col in new_df.columns]\n",
    "    new_df[\"score_text\"] = new_df[\"score_text\"].apply(lambda x: 0 if x==\"Low\" else 1)\n",
    "    new_df[\"sex\"] = new_df[\"sex\"].apply(lambda x: 0 if x == \"Male\" else 1)\n",
    "    new_df[\"c_charge_degree\"] = new_df[\"c_charge_degree\"].apply(lambda x: 0 if x == \"F\" else 1)\n",
    "    new_df = pd.get_dummies(new_df, \n",
    "                            columns = [\"age_cat\"],\n",
    "                            drop_first=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(data, response= \"score_text\"):\n",
    "    x = data.drop(response, axis = 1)\n",
    "    y = data[response]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "    x_train[response]=y_train\n",
    "    x_test[response]=y_test\n",
    "    return {\"train\":x_train, \"test\": x_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                           2\n",
      "age_cat                       3\n",
      "race                          6\n",
      "days_b_screening_arrest     423\n",
      "c_jail_in                  6907\n",
      "c_jail_out                 6880\n",
      "c_charge_degree               2\n",
      "is_recid                      2\n",
      "score_text                    3\n",
      "two_year_recid                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = [\"days_b_screening_arrest\",\n",
    "\"is_recid\",\n",
    "\"c_charge_degree\",\n",
    "\"c_jail_out\",\n",
    "\"c_jail_in\",\n",
    "\"age_cat\",\n",
    "\"race\",\n",
    "\"sex\",\n",
    "\"two_year_recid\",\n",
    "]\n",
    "recid = pd.read_csv(\"./compas_recid.csv\", usecols=cols+[\"score_text\"])\n",
    "print(recid.nunique())\n",
    "violent_recid = pd.read_csv(\"./compas_violent_recid.csv\", usecols=cols+[\"v_score_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "recid = splitter(compas_cleaning(recid))\n",
    "violent_recid = splitter(compas_cleaning(violent_recid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted true  Predicted false\n",
      "Is true         0.646995         0.353005\n",
      "Is false        0.282531         0.717469\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=500)\n",
    "model = model.fit(recid[\"train\"].drop(\"score_text\", axis = 1), recid[\"train\"][\"score_text\"])\n",
    "preds = model.predict(recid[\"test\"].drop(\"score_text\", axis = 1))\n",
    "print(confusion_matrix(recid[\"test\"][\"score_text\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(\"./propublica_data_for_fairml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = splitter(new_data, response = \"score_factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted true  Predicted false\n",
      "Is true         0.683060         0.316940\n",
      "Is false        0.194296         0.805704\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=500)\n",
    "model = model.fit(new_data[\"train\"].drop(\"score_factor\", axis = 1), new_data[\"train\"][\"score_factor\"])\n",
    "preds = model.predict(new_data[\"test\"].drop(\"score_factor\", axis = 1))\n",
    "print(confusion_matrix(new_data[\"test\"][\"score_factor\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = utils.load_compas_alt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6172"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priors_count                  4.743770\n",
       "two_year_recid                0.498022\n",
       "crime_factor                  0.479086\n",
       "gender_factor                 0.392629\n",
       "score_factor                  0.497086\n",
       "is_Caucasian                  0.473994\n",
       "age_factor_Greater than 45    0.406981\n",
       "age_factor_Less than 25       0.413087\n",
       "dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priors_count                  3.246436\n",
       "two_year_recid                0.455120\n",
       "crime_factor                  0.356773\n",
       "gender_factor                 0.809624\n",
       "score_factor                  0.445723\n",
       "is_Caucasian                  0.340732\n",
       "age_factor_Greater than 45    0.209494\n",
       "age_factor_Less than 25       0.218244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, alpha):\n",
    "    z = np.exp(-x+alpha)\n",
    "    sig = 1 / (1 + z)\n",
    "    return sig\n",
    "size = 6000\n",
    "priors_count = np.round(np.abs(np.random.uniform(3.246, 4.743, size = size)))\n",
    "two_year_recid = np.random.binomial(1,0.455, size = size)\n",
    "is_Caucasian = np.random.binomial(1,0.34, size = size)\n",
    "crime_factor = np.random.binomial(1,0.3567, size = size)\n",
    "age_greater_than_45 = np.random.binomial(1,0.209, size = size)\n",
    "age_less_than_25  = np.random.binomial(1,0.218, size = size)\n",
    "sex_male = np.random.binomial(1,0.809, size = size)\n",
    "score_text = np.around(sigmoid((priors_count*(0.1)+two_year_recid+is_Caucasian+crime_factor+\n",
    "age_greater_than_45+age_less_than_25+sex_male), alpha = 3)).astype(int)\n",
    "synth_cat = pd.DataFrame({\"score_factor\": score_text, \"priors_count\":priors_count,\n",
    "    \"two_year_recid\":two_year_recid, \"is_Caucasian\":is_Caucasian, \"crime_factor\":crime_factor,\n",
    "    \"age_factor_greater_than_45\":age_greater_than_45, \"age_factor_less_than_25\":age_less_than_25, \"sex_Male\":sex_male})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44033333333333335\n"
     ]
    }
   ],
   "source": [
    "print(synth_cat[\"score_factor\"].sum()/len(synth_cat[\"score_factor\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = splitter(formatted, response = \"score_factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted true  Predicted false\n",
      "Is true         0.692896         0.307104\n",
      "Is false        0.207665         0.792335\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=500)\n",
    "model = model.fit(formatted[\"train\"].drop(\"score_factor\", axis = 1), formatted[\"train\"][\"score_factor\"])\n",
    "preds = model.predict(formatted[\"test\"].drop(\"score_factor\", axis = 1))\n",
    "print(confusion_matrix(formatted[\"test\"][\"score_factor\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test to check if MCAR performance is still high even in the presence of missing data'\n",
    "formatted[\"train\"][\"bin\"] = np.random.binomial(n=1, p=0.40, size = len(formatted[\"train\"]))\n",
    "new_test = formatted.copy()\n",
    "new_test[\"train\"] = new_test[\"train\"][new_test[\"train\"][\"bin\"] == 1]\n",
    "new_test[\"train\"] = new_test[\"train\"].drop(\"bin\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted true  Predicted false\n",
      "Is true         0.719126         0.280874\n",
      "Is false        0.221925         0.778075\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=500)\n",
    "model = model.fit(new_test[\"train\"].drop(\"score_factor\", axis = 1), new_test[\"train\"][\"score_factor\"])\n",
    "preds = model.predict(new_test[\"test\"].drop(\"score_factor\", axis = 1))\n",
    "print(confusion_matrix(new_test[\"test\"][\"score_factor\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcar = np.random.binomial(n=1, p=0.5, size=len(formatted[\"train\"]))\n",
    "formatted[\"train\"][\"missing\"] = [1 if m == 1 else 0 for m in mcar]\n",
    "formatted[\"train\"][\"gender_factor\"] = formatted[\"train\"][\"gender_factor\"].mask(formatted[\"train\"][\"missing\"] == 1,\n",
    "                                            other=np.nan)\n",
    "formatted[\"train\"] = formatted[\"train\"].drop(\"missing\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5025    1.0\n",
       "3098    0.0\n",
       "1187    NaN\n",
       "5238    NaN\n",
       "4270    NaN\n",
       "       ... \n",
       "3772    1.0\n",
       "5191    NaN\n",
       "5226    NaN\n",
       "5390    NaN\n",
       "860     1.0\n",
       "Name: gender_factor, Length: 4135, dtype: float64"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted[\"train\"][\"missing\"] = [1 if m == 1 else 0 for m in mcar]\n",
    "formatted[\"train\"][\"gender_factor\"].mask(formatted[\"train\"][\"missing\"] == 1,\n",
    "                                            other=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priors_count                     0\n",
       "two_year_recid                   0\n",
       "crime_factor                     0\n",
       "gender_factor                 2044\n",
       "is_Caucasian                     0\n",
       "age_factor_Greater than 45       0\n",
       "age_factor_Less than 25          0\n",
       "score_factor                     0\n",
       "bin                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted[\"train\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted[\"train\"])-len(formatted[\"train\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b5d6a7d9324dc6141b12d74f79997d922c129aaadb2c82c0fa5c003a2c41f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

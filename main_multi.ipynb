{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_regular = utils.load_synthetic()\n",
    "compas = utils.load_compas_alt()\n",
    "RESPONSE = \"score_factor\"\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'test'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compas[\"standard\"][\"train\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  test\n",
      "Caucasian = 1:  0.35935935935935936 \n",
      "Caucasian = 0:  0.6406406406406406\n",
      "Male = 1:  0.8113113113113113 \n",
      "Male = 0:  0.18868868868868868\n",
      "After 30% missing: \n",
      "Caucasian = 1:  0.34206349206349207 \n",
      "Caucasian = 0:  0.6579365079365079\n",
      "Male = 1:  0.8428571428571429 \n",
      "Male = 0:  0.15714285714285714\n",
      "Key:  train\n",
      "Caucasian = 1:  0.33758120939530234 \n",
      "Caucasian = 0:  0.6624187906046977\n",
      "Male = 1:  0.8050974512743628 \n",
      "Male = 0:  0.19490254872563717\n",
      "After 30% missing: \n",
      "Caucasian = 1:  0.30178639300646143 \n",
      "Caucasian = 0:  0.6982136069935386\n",
      "Male = 1:  0.8350437096161155 \n",
      "Male = 0:  0.16495629038388446\n"
     ]
    }
   ],
   "source": [
    "#Checking that the classes don't become too much more imbalanced when data is removed.\n",
    "\n",
    "#Synthetic data\n",
    "for key, value in synth_regular.items():\n",
    "    #print(value.columns)\n",
    "    print(\"Key: \", key)\n",
    "    print(\"Caucasian = 1: \",len(value[value[\"is_Caucasian\"]==1])/len(value) ,\n",
    "    \"\\nCaucasian = 0: \", len(value[value[\"is_Caucasian\"]==0])/len(value))\n",
    "    print(\"Male = 1: \",len(value[value[\"gender_factor\"]==1])/len(value) ,\n",
    "    \"\\nMale = 0: \", len(value[value[\"gender_factor\"]==0])/len(value))\n",
    "    print(\"After 30% missing: \")\n",
    "    temp = value.copy()\n",
    "    temp = utils.impute(utils.data_remover_cat(temp, \"is_Caucasian\", 30), \"is_Caucasian\")\n",
    "    print(\"Caucasian = 1: \",len(temp[temp[\"is_Caucasian\"]==1])/len(temp) ,\n",
    "        \"\\nCaucasian = 0: \", len(temp[temp[\"is_Caucasian\"]==0])/len(temp))\n",
    "    print(\"Male = 1: \",len(temp[temp[\"gender_factor\"]==1])/len(temp) ,\n",
    "        \"\\nMale = 0: \", len(temp[temp[\"gender_factor\"]==0])/len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:  train\n",
      "Caucasian = 1:  0.3388149939540508 \n",
      "Caucasian = 0:  0.6611850060459492\n",
      "Male = 1:  0.8099153567110037 \n",
      "Male = 0:  0.19008464328899638\n",
      "Score text:  0.44401451027811367\n",
      "After 30% missing: \n",
      "Caucasian = 1:  0.32952924393723254 \n",
      "Caucasian = 0:  0.6704707560627675\n",
      "Male = 1:  0.8088445078459344 \n",
      "Male = 0:  0.19115549215406563\n",
      "Score text:  0.44401451027811367\n",
      "Key:  test\n",
      "Caucasian = 1:  0.3446244477172312 \n",
      "Caucasian = 0:  0.6553755522827688\n",
      "Male = 1:  0.8090328915071183 \n",
      "Male = 0:  0.19096710849288168\n",
      "Score text:  0.4491899852724595\n",
      "After 30% missing: \n",
      "Caucasian = 1:  0.3361462728551336 \n",
      "Caucasian = 0:  0.6638537271448663\n",
      "Male = 1:  0.7883263009845288 \n",
      "Male = 0:  0.21167369901547117\n",
      "Score text:  0.4491899852724595\n"
     ]
    }
   ],
   "source": [
    "#Compas data\n",
    "\"\"\"for ver in [\"standard\", \"violent\"]:\n",
    "    print(\"Compas dataset type: \", ver)\"\"\"\n",
    "for key, value in compas.items():\n",
    "    #print(value.columns)\n",
    "    print(\"Key: \", key)\n",
    "    print(\"Caucasian = 1: \",len(value[value[\"is_Caucasian\"]==1])/len(value) ,\n",
    "    \"\\nCaucasian = 0: \", len(value[value[\"is_Caucasian\"]==0])/len(value))\n",
    "    print(\"Male = 1: \",len(value[value[\"gender_factor\"]==1])/len(value) ,\n",
    "    \"\\nMale = 0: \", len(value[value[\"gender_factor\"]==0])/len(value))\n",
    "    print(\"Score text: \", len(value[value[\"score_factor\"]==1])/len(value))\n",
    "    print(\"After 30% missing: \")\n",
    "    temp = value.copy()\n",
    "    temp = utils.impute(utils.data_remover_cat(temp, \"is_Caucasian\", 30), \"is_Caucasian\")\n",
    "    print(\"Caucasian = 1: \",len(temp[temp[\"is_Caucasian\"]==1])/len(temp) ,\n",
    "        \"\\nCaucasian = 0: \", len(temp[temp[\"is_Caucasian\"]==0])/len(temp))\n",
    "    print(\"Male = 1: \",len(temp[temp[\"gender_factor\"]==1])/len(temp) ,\n",
    "        \"\\nMale = 0: \", len(temp[temp[\"gender_factor\"]==0])/len(temp))\n",
    "    print(\"Score text: \", len(value[value[\"score_factor\"]==1])/len(value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:16<00:00, 76.04s/it]\n",
      "100%|██████████| 1/1 [02:01<00:00, 121.89s/it]\n",
      "100%|██████████| 1/1 [01:28<00:00, 88.52s/it]\n",
      "100%|██████████| 1/1 [01:56<00:00, 116.55s/it]\n",
      "100%|██████████| 1/1 [01:27<00:00, 87.84s/it]\n",
      "100%|██████████| 1/1 [02:09<00:00, 129.38s/it]\n",
      "100%|██████████| 1/1 [01:29<00:00, 89.93s/it]\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.01s/it]\n",
      "100%|██████████| 1/1 [01:28<00:00, 88.65s/it]\n",
      "100%|██████████| 1/1 [01:48<00:00, 108.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "percentiles = [p for p in range(0,20,2)]+[p for p in range(20,60, 10)]\n",
    "missing=[\"two_year_recid\"]#, \"is_Caucasian\", \"gender_factor\", \"crime_factor\"]\n",
    "all_results = {}\n",
    "for miss in missing:\n",
    "    for sensitive in [\"is_Caucasian\"]:#, \"gender_factor\"]:\n",
    "        try:\n",
    "            synth_results = utils.test_bench(train = synth_regular[\"train\"],test = synth_regular[\"test\"], pred = RESPONSE, missing = miss, sensitive=sensitive,\n",
    "                            percentiles = percentiles)\n",
    "            recid_results = utils.test_bench(train = compas[\"train\"],test = compas[\"test\"], pred = RESPONSE, missing = miss, sensitive=sensitive,\n",
    "                            percentiles = percentiles)\n",
    "            #TODO and remember to fix data v_recid_results = utils.test_bench(train = compas[\"standard\"][\"train\"],test = compas[\"standard\"][\"test\"], pred = RESPONSE, missing = miss, sensitive=sensitive,\n",
    "                            #percentiles = percentiles)\n",
    "            temp_results[miss+\"_\"+sensitive+\"_\"+\"synth\"] = synth_results \n",
    "            temp_results[miss+\"_\"+sensitive+\"_\"+\"recid\"] = recid_results \n",
    "            #all_results[miss+\"_\"+sensitive+\"_\"+\"v_recid\"] = v_recid_results\n",
    "        except Exception as e:\n",
    "            print(\"Exception: \", e)\n",
    "            print(\"Parameters: \", sensitive+\"_\"+miss)\n",
    "    all_results[i] = temp_results \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "with open(Path(\"raw_data/multi.json\"), 'w') as f:\n",
    "            json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for key, res in all_results.items():\\n    utils.plotting_cf([\"log_reg\", \"rf_cat\", \"svm\", \"knn\"],[\"cca\", \"mice_def\", \"mean\"], res, key+\"/\")\\n    utils.plotting_others(res, key+\"/\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for key, res in all_results.items():\n",
    "    utils.plotting_cf([\"log_reg\", \"rf_cat\", \"svm\", \"knn\"],[\"cca\", \"mice_def\", \"mean\"], res, key+\"/\")\n",
    "    utils.plotting_others(res, key+\"/\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6b5d6a7d9324dc6141b12d74f79997d922c129aaadb2c82c0fa5c003a2c41f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

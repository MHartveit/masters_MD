{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fair_logistic_reg import FairLogisticRegression\n",
    "import numpy as np\n",
    "import utils\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family': 'normal',\n",
    "        'weight': 'bold',\n",
    "        'size': 25}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "IMPUTATIONS = [\"cca\", \"coldel\", \"mode\", \"mice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "compas = utils.load_compas_alt()\n",
    "train, test = compas[\"train\"], compas[\"test\"]\n",
    "RESPONSE = \"two_year_recid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eo_sum(pred, prot, true):\n",
    "    \"\"\"\n",
    "    Equation: |P(Y_pred = y_pred | Y_true = y_true, Z = 1) - P(Y_pred = y_pred | Y_true = y_true, Z = 0)|\n",
    "    Assumes prot is 0/1 binary\"\"\"\n",
    "    z1_y0 = [y_hat for y_hat, z, y in zip(\n",
    "        pred, prot, true) if z == 1 and y == 0]\n",
    "    z0_y0 = [y_hat for y_hat, z, y in zip(\n",
    "        pred, prot, true) if z == 0 and y == 0]\n",
    "    z1_y1 = [y_hat for y_hat, z, y in zip(\n",
    "        pred, prot, true) if z == 1 and y == 1]\n",
    "    z0_y1 = [y_hat for y_hat, z, y in zip(\n",
    "        pred, prot, true) if z == 0 and y == 1]\n",
    "    return abs(sum(z1_y1)/len(z1_y1)-sum(z0_y1)/len(z0_y1)) + abs(sum(z1_y0)/len(z1_y0)-sum(z0_y0)/len(z0_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, alpha):\n",
    "    z = np.exp(-x+alpha)\n",
    "    sig = 1 / (1 + z)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(true, pred):\n",
    "    # Assumes numpy arrays(\n",
    "    try:\n",
    "        tpr = sum([1 if t == p and p == 1 else 0 for t,\n",
    "                  p in zip(true, pred)])/(sum(true))\n",
    "    except:\n",
    "        tpr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "\n",
    "    try:\n",
    "        tnr = sum([1 if t == p and p == 0 else 0 for t,\n",
    "                  p in zip(true, pred)])/(len(true)-sum(true))\n",
    "    except:\n",
    "        tnr = 0\n",
    "        #print(\"true\", sum(true))\n",
    "        #print(\"pred\", sum(pred))\n",
    "    fpr = 1-tnr\n",
    "    fnr = 1-tpr\n",
    "    #Old return structure. Converted to vanilla dict for json compatibility\n",
    "    #return pd.DataFrame({\"Predicted true\": [tpr, fpr],\n",
    "    #                     \"Predicted false\": [fnr, tnr]}, index=[\"Is true\", \"Is false\"])\n",
    "    return {\"Predicted true\": [tpr, fpr],\n",
    "            \"Predicted false\": [fnr, tnr]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'log_reg = CustomLogisticRegression()\\nlog_reg.fit(train.drop(RESPONSE, axis = 1), train[RESPONSE])\\n\\nflr_orig = FairLogisticRegression(lam = 0.0)\\nflr_orig.pre_fit(train.drop(RESPONSE, axis = 1), train[RESPONSE])\\nflr_mod = FairLogisticRegression(model = log_reg, fairness_metric=\"eo_sum\")\\nflr_mod.fit_predicitve(train.drop(RESPONSE, axis = 1), train[RESPONSE])\\nflr_lam1 = FairLogisticRegression(model = log_reg, fairness_metric=\"eo_sum\", lam=1.0)\\nflr_lam1.fit_predicitve(train.drop(RESPONSE, axis = 1), train[RESPONSE])'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "compas = utils.load_compas_alt()\n",
    "train, test = compas[\"train\"].copy(), compas[\"test\"].copy()\n",
    "test[\"priors_count\"] = test[\"priors_count\"].apply(lambda x: 1 if x>0 else 0)\n",
    "train[\"priors_count\"] = train[\"priors_count\"].apply(lambda x: 1 if x>0 else 0)\n",
    "train[\"miss\"] =np.around(sigmoid(train[\"crime_factor\"] +train[\"gender_factor\"] + train[\"is_Caucasian\"] + train[\"age_factor_Greater than 45\"] + train[\"age_factor_Less than 25\"] + train[\"two_year_recid\"], 1)).astype(int)\n",
    "#x_miss = train[train[\"priors_count\"].isnull()].drop(\"priors_count\",axis = 1)\n",
    "#log_reg = LogisticRegression()\n",
    "from custom_log_reg import CustomLogisticRegression\n",
    "\"\"\"log_reg = CustomLogisticRegression()\n",
    "log_reg.fit(train.drop(RESPONSE, axis = 1), train[RESPONSE])\n",
    "\n",
    "flr_orig = FairLogisticRegression(lam = 0.0)\n",
    "flr_orig.pre_fit(train.drop(RESPONSE, axis = 1), train[RESPONSE])\n",
    "flr_mod = FairLogisticRegression(model = log_reg, fairness_metric=\"eo_sum\")\n",
    "flr_mod.fit_predicitve(train.drop(RESPONSE, axis = 1), train[RESPONSE])\n",
    "flr_lam1 = FairLogisticRegression(model = log_reg, fairness_metric=\"eo_sum\", lam=1.0)\n",
    "flr_lam1.fit_predicitve(train.drop(RESPONSE, axis = 1), train[RESPONSE])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train[train[\"miss\"] == 0].copy()\n",
    "temp.drop(\"miss\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"aaa\".split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors_count</th>\n",
       "      <th>crime_factor</th>\n",
       "      <th>gender_factor</th>\n",
       "      <th>is_Caucasian</th>\n",
       "      <th>age_factor_Greater than 45</th>\n",
       "      <th>age_factor_Less than 25</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      priors_count  crime_factor  gender_factor  is_Caucasian  \\\n",
       "3362             1             0              1             0   \n",
       "3993             0             0              0             0   \n",
       "4060             1             0              0             0   \n",
       "2549             0             0              0             0   \n",
       "4808             1             0              1             0   \n",
       "\n",
       "      age_factor_Greater than 45  age_factor_Less than 25  two_year_recid  \n",
       "3362                           0                        0               0  \n",
       "3993                           0                        0               1  \n",
       "4060                           0                        0               0  \n",
       "2549                           0                        0               0  \n",
       "4808                           0                        0               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING WEIGHTS [-2.13635375e+02  2.19318332e+03 -1.99782588e+00  3.49126486e+00\n",
      " -8.65807904e+01 -4.20432332e+02]\n",
      "STARTING FRACTION OF TRUE PRED 0.8073047858942065\n",
      "ENDING WEIGHTS [-298.37977811 2654.67481997  178.27420487  176.59404177  177.49426371\n",
      " -615.78949471]\n",
      "ENDING FRACTION OF TRUE PRED 0.8400503778337531\n",
      "STARTING WEIGHTS [-2.13635375e+02  2.19318332e+03 -1.99782588e+00  3.49126486e+00\n",
      " -8.65807904e+01 -4.20432332e+02]\n",
      "STARTING FRACTION OF TRUE PRED 0.8073047858942065\n",
      "ENDING WEIGHTS [ -61.64290455 2369.34183066  232.91815812  234.21257079  230.88655035\n",
      " -500.30348047]\n",
      "ENDING FRACTION OF TRUE PRED 0.8400503778337531\n",
      "STARTING WEIGHTS [-2.13635375e+02  2.19318332e+03 -1.99782588e+00  3.49126486e+00\n",
      " -8.65807904e+01 -4.20432332e+02]\n",
      "STARTING FRACTION OF TRUE PRED 0.8073047858942065\n",
      "ENDING WEIGHTS [ 104.57621174 2234.20508266  215.20404395  214.28417999  213.36729563\n",
      " -441.01823608]\n",
      "ENDING FRACTION OF TRUE PRED 0.871536523929471\n",
      "STARTING WEIGHTS [-2.13635375e+02  2.19318332e+03 -1.99782588e+00  3.49126486e+00\n",
      " -8.65807904e+01 -4.20432332e+02]\n",
      "STARTING FRACTION OF TRUE PRED 0.8073047858942065\n",
      "ENDING WEIGHTS [ 147.50743286 2201.19888599  212.66443623  210.49521509  210.9203309\n",
      " -424.58817998]\n",
      "ENDING FRACTION OF TRUE PRED 0.871536523929471\n",
      "STARTING WEIGHTS [-2.13635375e+02  2.19318332e+03 -1.99782588e+00  3.49126486e+00\n",
      " -8.65807904e+01 -4.20432332e+02]\n",
      "STARTING FRACTION OF TRUE PRED 0.8073047858942065\n",
      "ENDING WEIGHTS [ 157.02662329 2193.18332207  212.4320765   209.58072135  210.90987599\n",
      " -420.43233162]\n",
      "ENDING FRACTION OF TRUE PRED 0.871536523929471\n"
     ]
    }
   ],
   "source": [
    "for l in [0.5, 0.8, 0.95, 0.99, 1.0]:\n",
    "    flr_orig = FairLogisticRegression(lam = l)\n",
    "    flr_orig.pre_fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], epochs = 300)\n",
    "    flr_orig.fit_predicitve(train.drop(RESPONSE, axis = 1), train[RESPONSE], epochs = 100)\n",
    "    print(\"STARTING WEIGHTS\", flr_orig.weights)\n",
    "    print(\"STARTING FRACTION OF TRUE PRED\", np.sum(flr_orig.predict(temp.drop(\"priors_count\", axis = 1)))/len(temp))\n",
    "    flr_orig.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[RESPONSE], temp[\"gender_factor\"], 200, \n",
    "                        data = temp.drop([RESPONSE, \"priors_count\"], axis = 1), missing = \"priors_count\")\n",
    "    print(\"ENDING WEIGHTS\", flr_orig.weights)\n",
    "    print(\"ENDING FRACTION OF TRUE PRED\", np.sum(flr_orig.predict(temp.drop(\"priors_count\", axis = 1)))/len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_reg.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flr_orig.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(log_reg.predict(train.drop(RESPONSE, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19201934703748488\n"
     ]
    }
   ],
   "source": [
    "temp = train[train[\"miss\"] == 0].copy()\n",
    "temp.drop(\"miss\", axis = 1)\n",
    "print(len(temp)/len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flr_orig.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[\"gender_factor\"], 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flr_lam1._sigmoid(temp.drop(\"priors_count\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(flr_lam1.predict(temp.drop(\"priors_count\", axis = 1)))/len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_miss = data[data[missing_col].isnull()].drop(missing_col,axis = 1)\\ny_hat = flr.predict(x_miss)\\ndata.loc[data[missing_col].isnull(),missing_col] = y_hat '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"x_miss = data[data[missing_col].isnull()].drop(missing_col,axis = 1)\n",
    "y_hat = flr.predict(x_miss)\n",
    "data.loc[data[missing_col].isnull(),missing_col] = y_hat \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.7]\n",
      "CUSTOM FAIR 0.38999999999999996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38999999999999996"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_fair( pred, prot):\n",
    "    z_1 = [y_hat for y_hat, z in zip(pred, prot) if z==1]\n",
    "    z_0 = np.array([y_hat for y_hat, z in zip(pred, prot) if z==0])\n",
    "    print(z_1)\n",
    "    print(\"CUSTOM FAIR\", np.sum([np.sum((z1 - z_0)**2) for z1 in z_1]))\n",
    "    return np.sum([np.sum((z1 - z_0)**2) for z1 in z_1])\n",
    "\n",
    "pred = [0.2,0.5,0.7, 0.5,0.5]\n",
    "prot = [1,0,1,0,0]\n",
    "custom_fair(pred,prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flr_lam1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flr_lam1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8480/660041629.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m flr_lam1.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[\"gender_factor\"], 1000, \n\u001b[0m\u001b[0;32m      2\u001b[0m                        data = temp.drop([RESPONSE, \"priors_count\"], axis = 1), missing = \"priors_count\")\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m flr_mod.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[\"gender_factor\"], 100, \n\u001b[0;32m      5\u001b[0m                        data = temp.drop([RESPONSE, \"priors_count\"], axis = 1), missing = \"priors_count\")\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flr_lam1' is not defined"
     ]
    }
   ],
   "source": [
    "flr_lam1.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[\"gender_factor\"], 1000, \n",
    "                       data = temp.drop([RESPONSE, \"priors_count\"], axis = 1), missing = \"priors_count\")\n",
    "\n",
    "flr_mod.fit(temp.drop(\"priors_count\", axis = 1), temp[\"priors_count\"], temp[\"gender_factor\"], 100, \n",
    "                       data = temp.drop([RESPONSE, \"priors_count\"], axis = 1), missing = \"priors_count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_miss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13068/3599133095.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_hat_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflr_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_miss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_hat_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflr_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_miss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"priors_count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"priors_count\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_hat_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_miss' is not defined"
     ]
    }
   ],
   "source": [
    "y_hat_orig = flr_orig.predict(x_miss)\n",
    "y_hat_mod = flr_mod.predict(x_miss)\n",
    "orig = train.copy()\n",
    "mod = train.copy()\n",
    "mod.loc[mod[\"priors_count\"].isnull(),\"priors_count\"] = y_hat_mod\n",
    "mod.drop(\"miss\", axis = 1, inplace = True)\n",
    "x_test = test.drop(RESPONSE,axis = 1)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(mod.drop(RESPONSE, axis = 1), mod[RESPONSE])\n",
    "for s in [0,1]:\n",
    "    y_test = test[test[\"gender_factor\"]==s]\n",
    "    y_test = y_test[RESPONSE].astype(int)\n",
    "    pred = clf.predict(x_test[x_test[\"gender_factor\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))\n",
    "orig.loc[orig[\"priors_count\"].isnull(),\"priors_count\"] = y_hat_orig\n",
    "\n",
    "\n",
    "orig.drop(\"miss\", axis = 1, inplace = True)\n",
    "x_test = test.drop(RESPONSE,axis = 1)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(orig.drop(RESPONSE, axis = 1), orig[RESPONSE])\n",
    "for s in [0,1]:\n",
    "    y_test = test[test[\"gender_factor\"]==s]\n",
    "    y_test = y_test[RESPONSE].astype(int)\n",
    "    pred = clf.predict(x_test[x_test[\"gender_factor\"]==s])\n",
    "    print(pred.sum()-len(pred))\n",
    "    print(\"z=1\", confusion_matrix(y_test, pred))\n",
    "    print(\"accuracy\", accuracy_score(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6b5d6a7d9324dc6141b12d74f79997d922c129aaadb2c82c0fa5c003a2c41f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
